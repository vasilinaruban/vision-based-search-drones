from __future__ import annotations

import logging
import subprocess
from pathlib import Path
from typing import Dict

import mlflow
from omegaconf import DictConfig, OmegaConf
import yaml


from ultralytics import YOLO

LOGGER = logging.getLogger(__name__)


PROJECT_ROOT = Path(__file__).resolve().parents[1]
PLOTS_DIR = PROJECT_ROOT / "plots"
CONFIGS_DIR = PROJECT_ROOT / "configs"


def _ensure_dataset(cfg: DictConfig) -> Path:

    dataset_root = Path(cfg.data.dataset.path)

    if dataset_root.exists():
        LOGGER.info("Dataset directory exists: %s", dataset_root)
        return dataset_root

    LOGGER.warning("Dataset directory %s does not exist, trying `dvc pull`", dataset_root)
    try:
        subprocess.run(["dvc", "pull"], cwd=PROJECT_ROOT, check=True)
    except FileNotFoundError:
        LOGGER.error(
            "dvc is not installed or not found in PATH. "
            "Install DVC or create dataset directory manually."
        )
    except subprocess.CalledProcessError as e:
        LOGGER.error("`dvc pull` failed with return code %s", e.returncode)

    if not dataset_root.exists():
        raise FileNotFoundError(
            f"Dataset path {dataset_root} does not exist even after `dvc pull`. "
            "Check DATASET_PATH env or configs/data.yaml."
        )

    return dataset_root


def _create_yolo_data_yaml(cfg: DictConfig, dataset_root: Path) -> Path:

    yolo_cfg: Dict[str, object] = {
        "path": str(dataset_root),
        "train": cfg.data.dataset.train,
        "val": cfg.data.dataset.val,
        "test": cfg.data.dataset.test,
        "nc": int(cfg.data.dataset.classes),
        "names": list(cfg.data.dataset.class_names),
    }

    out_path = CONFIGS_DIR / "yolo_data_autogenerated.yaml"
    out_path.parent.mkdir(parents=True, exist_ok=True)
    with out_path.open("w", encoding="utf-8") as f:
        yaml.safe_dump(yolo_cfg, f, allow_unicode=True)
    LOGGER.info("YOLO data config written to: %s", out_path)
    return out_path


def _setup_mlflow(cfg: DictConfig) -> None:
    exp_cfg = cfg.experiment
    tracking_uri = exp_cfg.logger.tracking_uri
    experiment_name = exp_cfg.logger.experiment_name

    mlflow.set_tracking_uri(tracking_uri)
    mlflow.set_experiment(experiment_name)
    LOGGER.info("MLflow tracking URI: %s, experiment: %s", tracking_uri, experiment_name)


def _log_hparams_to_mlflow(cfg: DictConfig) -> None:

    params = OmegaConf.to_container(cfg.training, resolve=True)
    if isinstance(params, dict):
        mlflow.log_params(params)

    mlflow.log_param("model_name", cfg.model.name)
    mlflow.log_param("model_pretrained", cfg.model.pretrained)

    try:
        import git  # type: ignore[import]

        repo = git.Repo(PROJECT_ROOT, search_parent_directories=True)
        mlflow.log_param("git_commit", repo.head.commit.hexsha)
    except Exception as exc:  # best-effort
        LOGGER.warning("Could not log git commit: %s", exc)


def _log_metrics_to_mlflow(results) -> None:
    logged = 0
    candidates = []

    for attr in ("results_dict", "metrics", "metrics_dict"):
        if hasattr(results, attr):
            obj = getattr(results, attr)
            if isinstance(obj, dict):
                candidates.append(obj)

    for metrics in candidates:
        for key, value in metrics.items():
            try:
                mlflow.log_metric(str(key), float(value))
                logged += 1
                if logged >= 5:
                    return
            except Exception:
                continue

    if logged == 0:
        LOGGER.warning("No train metrics were logged to MLflow (structure of results is unknown).")


def _collect_and_log_plots(run_output_dir: Path) -> None:
    PLOTS_DIR.mkdir(parents=True, exist_ok=True)

    pngs = list(run_output_dir.rglob("*.png"))

    if not pngs:
        LOGGER.warning("No PNG plots found in %s", run_output_dir)
        return

    for src in pngs[:10]:
        dst = PLOTS_DIR / src.name
        try:
            dst.write_bytes(src.read_bytes())
            mlflow.log_artifact(str(dst), artifact_path="plots")
        except Exception as exc:
            LOGGER.warning("Could not copy or log plot %s: %s", src, exc)


def train(cfg: DictConfig) -> None:
    logging.basicConfig(level=logging.INFO)

    dataset_root = _ensure_dataset(cfg)
    data_yaml = _create_yolo_data_yaml(cfg, dataset_root)

    _setup_mlflow(cfg)

    weights = f"{cfg.model.name}.pt" if cfg.model.pretrained else cfg.model.name

    model = YOLO(weights)

    project_dir = PROJECT_ROOT / cfg.training.project

    with mlflow.start_run(run_name="train_yolov8"):

        _log_hparams_to_mlflow(cfg)

        results = model.train(
            data=str(data_yaml),
            epochs=cfg.training.epochs,
            imgsz=cfg.training.imgsz,
            batch=cfg.data.dataset.batch_size,
            device=cfg.training.device,
            project=str(project_dir),
            name="exp",
            exist_ok=True,
            single_cls=True,
            optimizer=cfg.training.optimizer,
            lr0=cfg.training.lr0,
            lrf=cfg.training.lrf,
            momentum=cfg.training.momentum,
            weight_decay=cfg.training.weight_decay,
            warmup_epochs=cfg.training.warmup_epochs,
            warmup_momentum=cfg.training.warmup_momentum,
            warmup_bias_lr=cfg.training.warmup_bias_lr,
            multi_scale=cfg.training.multi_scale,
            degrees=cfg.training.degrees,
            translate=cfg.training.translate,
            scale=cfg.training.scale,
            shear=cfg.training.shear,
            perspective=cfg.training.perspective,
            mixup=cfg.training.mixup,
            cos_lr=cfg.training.cos_lr,
            close_mosaic=cfg.training.close_mosaic,
            box=cfg.training.box,
            cls=cfg.training.cls,
            dfl=cfg.training.dfl,
            dropout=cfg.training.dropout,
        )

        try:
            _log_metrics_to_mlflow(results)
        except Exception as exc:
            LOGGER.warning("Could not log metrics to MLflow: %s", exc)

        try:
            run_output_dir = Path(getattr(model, "trainer", results).save_dir)
        except Exception:
            run_output_dir = project_dir

        _collect_and_log_plots(run_output_dir)
        try:
            LOGGER.info("Exporting trained model to ONNX for deployment")
            onnx_path = model.export(format="onnx")
            mlflow.log_artifact(str(onnx_path), artifact_path="export")
        except Exception as exc:
            LOGGER.warning("Could not export model to ONNX: %s", exc)

    LOGGER.info("Training finished. See MLflow UI and plots/ directory for details.")
